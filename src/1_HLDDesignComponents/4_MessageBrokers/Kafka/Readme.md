# :star: Apache Kafka 
- Apache Kafka is an [open-source distributed event streaming platform](../../0_SystemGlossaries/MessageBrokers/EventDrivenArchitecture.md) used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.
- Kafka is based on [Publish-Subscriber Model](../../0_SystemGlossaries/MessageBrokers/PubSubModel.md). And can be used for [Event-Driven Architecture](../../0_SystemGlossaries/MessageBrokers/EventDrivenArchitecture.md).
- Kafka can process a large amount of data in a short amount of time (1 million messages/sec).
- It also has [low latency](../../0_SystemGlossaries/Scalability/LatencyThroughput.md), making it possible to process data in real-time.
- [Amazon Managed Streaming for Apache Kafka (MSK)](../../../2_AWSComponents/5_MessageBrokerServices/AmazonMSK.md) can be used to deploy Kafka on [AWS](../../../2_AWSComponents).

# Basic Architecture of Kafka Cluster

![img.png](../assests/Kafka-Architecture.drawio.png)

# :star: Real world use cases of Kafka
- [Personalization at Spotify using Cassandra](../../../3_HLDDesignProblems/PersonalizationSpotify)
- [Zomato - HLD Design](../../../3_HLDDesignProblems/ZomatoDesign)
- [Uber Driver Allocation](../../../3_HLDDesignProblems/UberDriverAllocationDesign)
- [Twillo - Send Message API Design](../../../3_HLDDesignProblems/TwilloSendMessageAPI)
- [Logging Solution in Distributed Systems](../../../3_HLDDesignProblems/LoggingSolution)
- [Flight Booking Search](../../../3_HLDDesignProblems/FlightBookingSearch/README.md)
- [LinkedIn - Kafka](../../../3_HLDDesignProblems/LinkedInDesign/Readme.md)

# General use cases of Kafka

| Use Case                                                                                                                       | Description                                                                                                                                                                                                                                                                                                                                |
|--------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| As an events/message broker in [Event-Driven Architecture](../../0_SystemGlossaries/MessageBrokers/EventDrivenArchitecture.md) | Use Kafka when your application has a High Throughput (around `1 million messages/sec`), i.e. application has to process a large volume of messages, [event driven services](../../0_SystemGlossaries/MessageBrokers/EventDrivenArchitecture.md) etc.                                                                                      |
| To monitor metrics, logs of the IT infrastructure                                                                              | Various systems in the IT infrastructure can push events/messages/logs in the Kafka. And [logstash (in ELK)](../../8_MonitoringTools/ELK.md) can act as a consumer to the Kafka.                                                                                                                                                           |
| For Analytics                                                                                                                  | If we want to build our own Google Analytics (to track app activities, events etc.), we can use Kafka as a broker.                                                                                                                                                                                                                         |
| [Stream Processing](../../5_BigDataComponents/StreamProcessing/Readme.md)                                                      | Use [Kafka Stream API](../../5_BigDataComponents/StreamProcessing/KafkaStreamsAPI.md) when the event stream needs to process data in multi-stage pipelines, the pipelines can generate graphs of the real-time data flows, thus providing real-time monitoring of traffic in the pipelines.<br/>- Example - Video streaming in YouTube etc. |

# Top Features of Kafka

| Feature                                | Description                                                                                                                                                                                                                                                                                                                                                                                        |
|----------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Scalability                            | Kafka can be [horizontally scaled](../../0_SystemGlossaries/Scalability/DBScalability.md) easily across the cluster.<br/>- A cluster of brokers is used to partition and streamline the data thereby, scaling up the storage capacity.                                                                                                                                                             |
| Performance - High Throughput          | Each Kafka broker can serve more than [1 million messages per second](../../0_SystemGlossaries/Scalability/LatencyThroughput.md#Throughput) and can hold TBs of data.<br/>- Default configured message size in Kafka is `1MB`.                                                                                                                                                                     |
| High Volume                            | Large amount of data can be stored in the Kafka pool.                                                                                                                                                                                                                                                                                                                                              |
| Durability                             | The data is kept [persistent (as per retention policy)](../../0_SystemGlossaries/Database/Durability.md) and tolerant to any hardware failures by copying the data in the clusters.                                                                                                                                                                                                                |
| High Availability, Fault Tolerance     | The [distributed, partitioned, replicated](../../0_SystemGlossaries/Database/ReplicationAndDataConsistency.md), and [fault-tolerant](../../0_SystemGlossaries/Reliability/FaultTolerance.md) nature of Kafka makes it very reliable.<br/>- Kafka connector can handle failures with three strategies summarised as `fast-fail`, `ignore` and `re-queue` (sends to another topic). |
| Extensibility                          | Allows multiple ways for applications to plugin and make use of Kafka.<br/>- Also, it has provisions for new connectors that you can write as needed.                                                                                                                                                                                                                                              |
| Data Transformation                    | Using [Kafka Stream API](../../5_BigDataComponents/StreamProcessing/KafkaStreamsAPI.md), Kafka allows for deriving new data streams using the existing data streams from producers.                                                                                                                                                                                                                                                            |

# Major Components of Kafka

| Component                                                                                     | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
|-----------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Topic (i.e. Stream or Category or Queue)](../../0_SystemGlossaries/MessageBrokers/Readme.md) | Topic is a category or feed where messages (or events) would be saved and published.                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| [Producer](../../0_SystemGlossaries/MessageBrokers/Readme.md)                                 | Producer writes data into the topics (1 or more) in the Kafka.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| [Consumer](../../0_SystemGlossaries/MessageBrokers/Readme.md)                                 | A consumer can subscribe ( listen ) to the topics ( 1 or more ) and read data from those in the Kafka.<br/>- Reading data out of Kafka is very fast thanks to `java.nio.channels.FileChannel#transferTo`.<br/>- This method uses `sendFile` system call which allows for very efficient transfer of data from a file to another file ( including sockets ).                                                                                                                                                                                     |
| Consumer Group                                                                                | A consumer group in Kafka is a collection of consumers who work together to ingest data from the same topic or range of topics.<br/>-                                                                                                                                                                                                                                                                                                                                                                                                           |
| Broker (i.e. Server)                                                                          | A Kafka cluster is made up of a number of brokers (servers), which provides load balancing, reliable redundancy & fail-over.<br/>- Without sacrificing performance, each broker instance can handle read and write volumes of hundreds of thousands per second (and gigabytes of messages).                                                                                                                                                                                                                                                     |
| [Partitioning](../../0_SystemGlossaries/MessageBrokers/Readme.md)                             | Topics can be parallelized via partitions, which split data into a single topic among numerous brokers.                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| [Partition Key](../../0_SystemGlossaries/MessageBrokers/Readme.md)                            | Partition key helps in maintaining the order of the messages.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| Partition - Replication                                                                       | Each partition would be replicated across the brokers/servers in the cluster (as per configured replication factor).                                                                                                                                                                                                                                                                                                                                                                                                                            |
| Partition - Leader                                                                            | Only one partition (of the topic) would be active at the time, called `Leader`.<br/>- Write requests on the partition, would be handled by Leader.                                                                                                                                                                                                                                                                                                                                                                                              |
| Partition - Follower                                                                          | Other partitions (of the topic) would only replicate message, called `Followers`.<br/>- Based on configured replication factor ([replication.factor](https://kafka.apache.org/documentation/#replication)), the number of followers would be decided.<br/>- Example - 3 replication factor means there would be 1 leader and 2 followers.                                                                                                                                                                                                       |
| [Zookeeper](../../7_ClusterCoordinationService/ApacheZookeeper.md)                            | [Zookeeper](../../7_ClusterCoordinationService/ApacheZookeeper.md) manages Kafka Cluster (new broker, new partition etc.), brokers coordination & election process (leader, Controller election etc.)                                                                                                                                                                                                                                                                                                                                           |
| [Log Compaction](../../0_SystemGlossaries/MessageBrokers/Readme.md)                           | [Read more](https://medium.com/swlh/introduction-to-topic-log-compaction-in-apache-kafka-3e4d4afd2262)                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| [Core APIs in Kafka](KafkaAPIs.md)                                                            | [Kafka HTTP APIs](https://www.confluent.io/blog/http-and-rest-api-use-cases-and-architecture-with-apache-kafka/) can be integrated in the client apis, to push the message to the specific topic (& partition key).                                                                                                                                                                                                                                                                                                                             |
| In-Sync Replicas (ISR)                                                                        | An [in-sync replica (ISR)](https://www.conduktor.io/blog/how-replication-and-isr-work-in-kafka) is a broker that has the latest data for a given partition.<br/>- A leader is always an in-sync replica.<br/>- A follower is an in-sync replica only if it has fully caught up to the partition it’s following.<br/>- Read requests on the partition, would be handled by in-sync replicas.                                                                                                                                                     |
| ACK levels                                                                                    | `acks` denotes the number of brokers that must receive the record before we consider the write as successful.                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| ACK level - acks=0                                                                            | With a value of 0, the producer won’t even wait for a response from the broker.                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| ACK level - acks=1                                                                            | With a setting of 1, the producer will consider the write successful when the leader receives the record.<br/>- The leader broker will know to immediately respond the moment it receives the record and not wait any longer.                                                                                                                                                                                                                                                                                                                   |
| ACK level - acks=all                                                                          | When set to all, the producer will consider the write successful when all of the in-sync replicas receive the record.<br/>- This is achieved by the leader broker being smart as to when it responds to the request – it’ll send back a response once all the in-sync replicas receive the record themselves.                                                                                                                                                                                                                                   |
| Schema Registry                                                                               | Schema Registry holds Avro schemas & ensures that schema used by producer and consumer, are identical.<br/>- Producer sends schema id while pushing the data and consumer look for schema id to get schema.                                                                                                                                                                                                                                                                                                                                     |
| Kafka Controller                                                                              | [The Kafka controller is brain of the Kafka cluster](https://stackoverflow.com/questions/49525141/how-many-kafka-controllers-are-there-in-a-cluster-and-what-is-the-purpose-of-a-c).<br/>- It monitors the liveliness of the brokers and acts on broker failures.<br/>- [Kafka Controller does leader election for the topic & in-charge of partition leaders and replication](https://stackoverflow.com/questions/49525141/how-many-kafka-controllers-are-there-in-a-cluster-and-what-is-the-purpose-of-a-c) ( if existing leader goes down ). |
| Security                                                                                      | All components ( brokers, zookeeper, producers, consumers etc. ) should authenticate each other and setup an encrypted (SSL) channel for communication.<br/>- `Authorization` - ACLs should be defined and enforced to control which users can perform what action?                                                                                                                                                                                                                                                                             |
| Kafka Cluster for high availability                                                           | A minimum in-sync replicas of 2.<br/>- A replication factor of 3 for topics.<br/>- At least 3 Kafka brokers, each running on different nodes.<br/>- Nodes spread across three availability zones.                                                                                                                                                                                                                                                                                                                                               |

# Partition Diagram

![img.png](../assests/Kafka-Partitioning-Layout.drawio.png)

# In-Sync Replicas (ISR)

![img.png](https://accu.org/journals/overload/28/159/kozlovski/2.png)

# ACK level - acks=1

![img.png](https://accu.org/journals/overload/28/159/kozlovski/4.png)

# ACK level - acks=all

![img.png](https://accu.org/journals/overload/28/159/kozlovski/6.png)

# Estimation - How to decide number of partitions in Kafka?

Rough formula for picking the number of partitions = `MAX(t/p, t/c)`

| Parameter | Title                            | More Description                                                                                  |
|-----------|----------------------------------|---------------------------------------------------------------------------------------------------|
| `t`       | Target Throughput                | Let’s say your target throughput is t.                                                            |
| `p`       | Throughput on a single partition | You measure the throughout that you can achieve on a single partition for production (call it p). |
| `c`       | Consumption Rate                 | And consumption (call it c).                                                                      |

Read more
- [How to Choose the Number of Topics/Partitions in a Kafka Cluster?](https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster/)
- [Kafka cluster size calculator](https://docs.google.com/spreadsheets/d/1a3uIa8TTRLlN6HTtMzPPqf8p5j5OxflJuAyff-uHLgk/edit?usp=sharing)

# Partitions - Considerations

| Consideration                                     | Remarks                                                                                                                                                              |
|---------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| More partitions lead to `higher throughput`       | -                                                                                                                                                                    |
| More partitions requires `more open file handles` | We have seen production Kafka clusters running with more than 30 thousand open file handles per broker.                                                              |
| More partitions may `increase unavailability`     | It’s probably better to limit the number of partitions per broker to two to four thousand and the total number of partitions in the cluster to low tens of thousand. |
| More partitions may increase end-to-end latency.  | As a rule of thumb, if you care about latency, it’s probably a good idea to limit the number of partitions per broker to *100 x b x r*, where b is the number of brokers in a Kafka cluster and r is the replication factor.                                                                                                                                                                     |

# Why Kafka is so fast?
- Kafka achieves [low latency](../../0_SystemGlossaries/Scalability/LatencyThroughput.md) message delivery through [Sequential I/O and Zero Copy Principle](https://twitter.com/alexxubyte/status/1506663791961919488/photo/1).
- Messages (events) in the [Kafka]() are immutable and can't be changed once it's pushed (due to [log based queue nature](../../0_SystemGlossaries/Database/AppendOnlyDataStructure.md)).
- The same techniques are commonly used in much other messaging/streaming platforms.

Kafka is based on [Log Based Queue](../../0_SystemGlossaries/Database/AppendOnlyDataStructure.md)
- :star: Messages are persisted to [append-only log files](../../0_SystemGlossaries/Database/AppendOnlyDataStructure.md) by the broker.
- Producers are [appending these log files (sequential write)](../../0_SystemGlossaries/Database/AppendOnlyDataStructure.md) & consumers are reading a range of these files ( `sequential reads` ).

# Other Links
- [Kafka vs Others](../KafkaVsRabbitMQVsSQSVsSNS.md)
- [Designing and testing a highly available Kafka cluster on Kubernetes (without zookeeper)](https://learnk8s.io/kafka-ha-kubernetes)

# References
- [Kafka official documentation](https://kafka.apache.org/documentation/#theproducer)
- [Kafka Interview Question](https://www.interviewbit.com/kafka-interview-questions/)
- [How to minimize the latency involved in kafka messaging framework?](https://stackoverflow.com/questions/20520492/how-to-minimize-the-latency-involved-in-kafka-messaging-framework)
- [Apache Kafka on AWS using Amazon MSK](https://aws.amazon.com/msk/what-is-kafka/)
- [Kafka Talk by Tri Hug](https://www.slideshare.net/mumrah/kafka-talk-tri-hug)
- [Role of ZooKeeper in Kafka](https://www.youtube.com/watch?v=bnHWrSwPvig)
- [Replication in Kafka](https://medium.com/@_amanarora/replication-in-kafka-58b39e91b64e)
- [Kafka Acks Explained](https://accu.org/journals/overload/28/159/kozlovski/)
- [Is Kafka a database?](https://queue.acm.org/detail.cfm?id=3321612)